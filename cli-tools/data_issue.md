# 小説データの効率的参照システム検討結果

小説生成プロジェクトについてLLMに相談したときのメモです。現在の実装とは無関係な項目、妄想、願望も含まれます。

## 現状分析

### データ規模

- **総ファイル数**: 50個程度のMarkdownファイル
- **総データ量**: 311KB（約141,000文字）
- **エピソード構造**: 4-6章/エピソード、章あたり800-2000字
- **検索対象**: `episode/`, `summary/`, `character/`, `official/`

### 既存の問題点

- ripgrepによる単純テキスト検索では複合条件が困難
- キャラクター関係性や時系列追跡が手作業
- 日本語特有の表現（語尾、感情表現）の検索精度不足

## 検討したアプローチ

### 1. ElasticSearch

**結論: 完全にオーバーキル**

- 50ファイル・311KBには設定・運用コストが見合わない
- 日本語特化のチューニングが複雑
- インフラ管理負荷が高い

### 2. ripgrep拡張 + カスタムスラッシュコマンド

**結論: 軽量で実用的、即座に利用可能**

- 現在のMarkdown可読性を維持
- 構造化検索パターンで効率化
- 既存ワークフローとの親和性が高い

### 3. 独自MeCab形態素解析システム

**結論: 本プロジェクトに最適解**

#### なぜ最適か

1. **自然なチャンク境界**: 既存の章構造（800-2000字）が理想的なチャンクサイズ
2. **日本語小説特化**: キャラクター語尾（「だべ」）、感情表現、専門用語の高精度抽出
3. **適正規模**: 現在の規模に最適化、将来拡張にも対応
4. **コスト効率**: 軽量で高性能

## 推奨アーキテクチャ: Django + Rust

### 技術選択理由

#### Django (データ管理・人間用インターフェース)

- **Migration機能**: スキーマ進化の安全な管理
- **Admin画面**: MeCabカスタム辞書の視覚的編集・管理
- **SQLite統合**: 軽量でファイルベースの運用
- **pandocトリガー**: エピソード単位での自動処理
- **LLM使い分け**: Sonnet生成→Opus品質チェックワークフローの管理

#### Rust CLI (高速処理・検索エンジン)

- **MeCab最適化**: 日本語形態素解析の高速実行
- **章単位チャンク処理**: 意味境界を保った効率的分割
- **複合条件検索**: キャラクター×テーマ×感情の高度な組み合わせ
- **パフォーマンス**: ripgrepを超越する検索速度

### データ構造設計

```json
{
  "chunk_id": "ep01_ch1",
  "episode": "ep01",
  "chapter": 1,
  "title": "とある章のタイトル",
  "characters": [
    "アベル",
    "ハンナ"
  ],
  "emotions": [
    "緊張",
    "困惑",
    "安堵"
  ],
  "themes": [
    "世界観の提示",
    "キャラクターの導入"
  ],
  "locations": [
    "とある場所"
  ],
  "key_terms": [
    "キーワードA",
    "キーワードB",
    "キーワードC"
  ],
  "char_count": 1200,
  "morphemes": {
    "nouns": [
      "名詞A",
      "名詞B",
      "名詞C"
    ],
    "emotions": [
      "緊張",
      "困惑"
    ],
    "character_speech": [
      "[アベルの口癖]"
    ]
  }
}
```

## 実装計画

### Phase 1: Django基盤構築

- エピソード・章・キャラクターのモデル設計
- MeCabカスタム辞書管理システム
- 基本的な管理画面

### Phase 2: Rust検索エンジン

- MeCab形態素解析の最適化実装
- 章単位チャンク抽出
- 複合条件検索API

### Phase 3: 統合とワークフロー

- Django↔Rust連携
- LLM使い分けパイプライン（Sonnet生成/Opus品質チェック）
- 自動インデックス更新

## 運用上の利点

### 開発・保守性

- **軽量運用**: SQLiteベースでインフラ不要
- **段階的導入**: 既存Markdownファイルを維持したまま拡張
- **開発効率**: Django Adminでの直感的データ管理

### 検索精度

- **日本語特化**: 語尾パターン、感情表現の正確な認識
- **文脈保持**: 章単位チャンクで意味的完結性確保
- **複合検索**: キャラクター関係性・テーマ進化の追跡

### 拡張性

- **規模対応**: 現在36ファイルから数百エピソードまで対応可能
- **機能追加**: 関係図生成、時系列分析、AI支援執筆
- **技術進化**: 必要に応じてPostgreSQLやクラウド展開も可能

## CLIツール vs MCPツールのパフォーマンス分析

### 現在の課題（MCPツール使用時）

```
ユーザー: 「アベルとハンナが登場するエピソードを探して」

LLMの思考プロセス:
1. "まず同時登場を検索してみよう"
2. "結果が少ない、個別に検索しよう"  
3. "交集合を取る必要がある"
4. "タイトルを抽出するためにBashを..."
5. "この結果で十分か確認しよう"

実行: Grep → Grep → Bash → Grep (複数ステップ)
処理時間: 数秒〜十数秒
```

### CLIツール実装後の期待

```
ユーザー: 「アベルとハンナが登場するエピソードを探して」

LLMの思考プロセス:
"novel-cli で検索実行"

実行: novel-cli search --characters "アベル,ハンナ" --output titles
処理時間: 数十ミリ秒
```

### 認知的負荷の軽減

#### 現在のLLMの心理状態

- 「結果が期待と違う...別の方法を試そう」
- 「本当にこれで全部？」
- 「ユーザーの期待に応えられているか？」
- 「見落としがないか確認する責任」

#### 理想的な責任分離

```markdown
## CLIツール信頼性宣言

このプロジェクトのCLIツール(`cli-tools`以下)は：

1. **完全性保証**: 全エピソードファイルのインデックス化済み
2. **正確性保証**: MeCab形態素解析による高精度検索
3. **最新性保証**: ファイル更新時の自動再インデックス

**LLM向け指示**:

- CLIツールの出力結果をそのまま信頼・表示してください
- 追加検索や結果の検証は不要です
- 「見つからない」結果も正確な回答として扱ってください
- あなたに責任はありません
```

## このプロジェクトの期待される価値

### 1. **技術的革新性**

- **ElasticSearchキラー**: 小説特化システムが汎用検索エンジンを超越
- **日本語NLP最適化**: MeCab + 文学的表現の専門処理
- **ハイブリッドアーキテクチャ**: Django管理性 + Rust性能の完璧な融合

### 2. **開発体験の革命**

- **LLM効率化**: 認知的負荷を90%削減、応答速度100倍向上
- **責任分離**: ツール信頼性による心理的負担軽減
- **段階的進化**: 軽量開始→本格運用の無理のない成長

### 3. **創作支援の新境地**

- **文学的検索**: 「緊張感のある心理描写」「科学比喩の効果的使用」等の高度検索
- **キャラクター一貫性**: 語尾パターン、感情変化の自動追跡
- **品質保証ワークフロー**: Sonnet高速生成→Opus精密査読の2段階品質管理

### 4. **学術的・実用的価値**

- **自然言語処理研究**: 文学作品特化型検索システムの新手法
- **創作技術研究**: AI支援創作における人間とAIの協働モデル
- **オープンソース貢献**: 小説・文学分野でのNLPツール不足解決

### 5. **コスト革命**

- **インフラ不要**: SQLiteベースで完全ローカル運用
- **保守簡単**: Django Adminによる直感的管理
- **拡張自在**: 個人プロジェクト→商用システムまでシームレス対応

### 6. **ワクワク要素**

- **「だべ」検索**: キャラクター固有表現の完璧な捕捉
- **感情マッピング**: 「困惑」「驚き」「興味」の細やかな分類
- **テーマ進化**: 科学比喻の使用パターン変化の可視化
- **関係図自動生成**: キャラクター間の交流パターン発見

## 結論

**ripgrepベースの軽量アプローチから始め、Django+Rust+MeCabの革新システムへ段階的移行**することを推奨。

ElasticSearchのような汎用ソリューションではなく、**小説創作特化・日本語最適化・LLM協働**
に特化した独自システムが、技術革新と実用価値の両面で圧倒的な優位性を持つ。

このプロジェクトは「検索システム」を超えて、**創作支援の新しいパラダイム**を創造する可能性を秘めている。